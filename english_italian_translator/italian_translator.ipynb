{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cea54d1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f2726df",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 30px;\"><b>Italian Translator</b></p>\n",
    "\n",
    "**Building an English-Italian Neural Machine Translator**\n",
    "\n",
    "### **Project Overview**\n",
    "\n",
    "This project implements a **sequence-to-sequence (seq2seq) neural machine translation system** that translates English sentences to Italian using deep learning.\n",
    "\n",
    "**What we're building:**\n",
    "- Encoder-decoder architecture with LSTM networks\n",
    "- Trained on 5,000 English-Italian sentence pairs\n",
    "- Word-by-word translation generation\n",
    "\n",
    "**Core components:**\n",
    "1. **Data preprocessing**: Tokenization, vocabulary building, one-hot encoding\n",
    "2. **Encoder**: Compresses English sentences into meaning vectors\n",
    "3. **Decoder**: Generates Italian translations from encoder states\n",
    "4. **Training**: Model learns translation patterns over 100+ epochs\n",
    "5. **Inference**: Word-by-word generation using trained models\n",
    "\n",
    "**Key technologies:**\n",
    "- **TensorFlow/Keras**: Neural network framework\n",
    "- **LSTM layers**: Handle sequential language data\n",
    "- **One-hot encoding**: Convert text to numerical format\n",
    "- **Greedy decoding**: Generate translations word-by-word\n",
    "\n",
    "**Learning goals:**\n",
    "- Understand seq2seq architecture\n",
    "- Master encoder-decoder connections\n",
    "- Learn autoregressive generation\n",
    "- Handle real-world NLP challenges (vocabulary size, overfitting, data quality)\n",
    "\n",
    "**Expected outcome:**\n",
    "A working translator that can accurately translate simple English sentences to Italian (for vocabulary seen during training).\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44b24f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 17:48:04.420943: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-07 17:48:04.440549: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-07 17:48:04.569180: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-07 17:48:04.707707: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765126084.835151   30725 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765126084.878932   30725 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-07 17:48:05.168610: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283a0bc",
   "metadata": {},
   "source": [
    "# **Data Loading and Preprocessing**\n",
    "\n",
    "### **Purpose:**\n",
    "Transform raw English-Italian text file into numerical matrices for neural network training.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Load Raw Data**\n",
    "```python\n",
    "data_path = \"ita.txt\"\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "```\n",
    "- Opens file with UTF-8 encoding (handles Italian accents)\n",
    "- Splits into list of lines (each line = one translation pair)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Initialize Data Structures**\n",
    "```python\n",
    "input_docs = []      # English sentences\n",
    "target_docs = []     # Italian sentences\n",
    "input_tokens = set() # Unique English words\n",
    "target_tokens = set() # Unique Italian words\n",
    "NUM_SAMPLES = 5000   # Use first 5000 sentences\n",
    "```\n",
    "- Lists store sentences; sets collect unique vocabulary\n",
    "- 5000 sentences balances learning quality with memory usage\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Process Each Sentence**\n",
    "```python\n",
    "for line in lines[:NUM_SAMPLES]:\n",
    "    input_doc, target_doc = line.split('\\t')[:2]\n",
    "```\n",
    "- Splits line on tab: `\"Go.\\tVai.\"` → English: `\"Go.\"`, Italian: `\"Vai.\"`\n",
    "\n",
    "**Tokenize (separate punctuation):**\n",
    "```python\n",
    "input_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc))\n",
    "# \"Go.\" → \"Go .\"\n",
    "# \"I'll try.\" → \"I'll try .\"\n",
    "```\n",
    "\n",
    "**Add special tokens to Italian:**\n",
    "```python\n",
    "target_doc = '<START> ' + target_doc + ' <END>'\n",
    "# \"Vai .\" → \"<START> Vai . <END>\"\n",
    "```\n",
    "- `<START>` signals decoder to begin translation\n",
    "- `<END>` signals when to stop generating\n",
    "\n",
    "**Build vocabularies:**\n",
    "```python\n",
    "for token in input_doc.split():\n",
    "    input_tokens.add(token)  # Sets auto-handle duplicates\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Prepare Vocabularies**\n",
    "```python\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "```\n",
    "- Sorting ensures consistent word→index mapping across runs\n",
    "- Count total unique words in each language\n",
    "\n",
    "**Calculate maximum sentence lengths:**\n",
    "```python\n",
    "max_encoder_seq_length = max([len(doc.split()) for doc in input_docs])\n",
    "max_decoder_seq_length = max([len(doc.split()) for doc in target_docs])\n",
    "```\n",
    "- Finds longest sentence (all sentences padded to this length)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Create Word↔Index Dictionaries**\n",
    "```python\n",
    "input_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n",
    "# {\"Go\": 0, \"Hi\": 1, \"I\": 2, ...}\n",
    "\n",
    "reverse_input_features_dict = dict((i, token) for token, i in input_features_dict.items())\n",
    "# {0: \"Go\", 1: \"Hi\", 2: \"I\", ...}\n",
    "```\n",
    "- Forward dict: converts words to numbers (encoding)\n",
    "- Reverse dict: converts numbers to words (decoding)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 6: Create Empty Training Matrices**\n",
    "```python\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "```\n",
    "**3D shape:**\n",
    "- Dimension 1: Number of sentences (5000)\n",
    "- Dimension 2: Max sentence length (e.g., 15 words)\n",
    "- Dimension 3: Vocabulary size (e.g., 939 English words)\n",
    "\n",
    "**Three matrices needed:**\n",
    "1. `encoder_input_data` - English sentences\n",
    "2. `decoder_input_data` - Italian with `<START>`\n",
    "3. `decoder_target_data` - Italian shifted (for learning)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 7: Fill Matrices (One-Hot Encoding)**\n",
    "```python\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "    for timestep, token in enumerate(input_doc.split()):\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "```\n",
    "\n",
    "**What happens:**\n",
    "- Loop through each sentence and word\n",
    "- Look up word's index in dictionary\n",
    "- Set that position to 1 (all others stay 0)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "\"Go .\" → tokens: [\"Go\", \".\"]\n",
    "\"Go\" is index 45 → encoder_input_data[0, 0, 45] = 1.\n",
    "\".\" is index 12  → encoder_input_data[0, 1, 12] = 1.\n",
    "```\n",
    "\n",
    "**Decoder target shift:**\n",
    "```python\n",
    "if timestep > 0:\n",
    "    decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\n",
    "```\n",
    "- Skips `<START>` token (timestep 0)\n",
    "- Creates shifted version for training\n",
    "- Decoder learns: input `<START>` → output `Vai`, input `Vai` → output `.`\n",
    "\n",
    "---\n",
    "\n",
    "### **Result:**\n",
    "\n",
    "✅ **5,000 sentence pairs processed**\n",
    "✅ **Vocabularies built** (English: ~939 words, Italian: ~2692 words)\n",
    "✅ **Three 3D matrices created** with one-hot encoded data\n",
    "✅ **Ready for model training**\n",
    "\n",
    "**Data flow:**\n",
    "```\n",
    "Raw text → Tokenization → Vocabularies → Dictionaries → One-hot matrices\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7cd3b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preprocessing sentences...\n",
      "Processed 5000 sentences\n",
      "English vocabulary: 939 tokens\n",
      "Italian vocabulary: 2692 tokens\n",
      "Max encoder sequence length: 6\n",
      "Max decoder sequence length: 10\n",
      "Creating training matrices...\n",
      "Filling matrices with one-hot encoded data...\n",
      "Processing sentence 0/5000...\n",
      "Processing sentence 1000/5000...\n",
      "Processing sentence 2000/5000...\n",
      "Processing sentence 3000/5000...\n",
      "Processing sentence 4000/5000...\n",
      "Data preprocessing complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "# Importing our translations\n",
    "data_path = \"ita.txt\"\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "  lines = f.read().split('\\n')\n",
    "\n",
    "# Building empty lists to hold sentences\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "# Building empty vocabulary sets\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "print(\"Preprocessing sentences...\")\n",
    "# Use fewer sentences to start - adjust based on RAM\n",
    "NUM_SAMPLES = 5000  # Start with 5000 instead of 10000\n",
    "\n",
    "for line in lines[:NUM_SAMPLES]:\n",
    "  # Input and target sentences are separated by tabs\n",
    "  input_doc, target_doc = line.split('\\t')[:2]\n",
    "  \n",
    "  # Apply fix: separate punctuation in input too\n",
    "  input_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc))\n",
    "  input_docs.append(input_doc)\n",
    "  \n",
    "  # Separate punctuation in target\n",
    "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "  target_doc = '<START> ' + target_doc + ' <END>'\n",
    "  target_docs.append(target_doc)\n",
    "  \n",
    "  # Build vocabularies - OPTIMIZED (removed if check, .add() handles duplicates)\n",
    "  for token in input_doc.split():\n",
    "    input_tokens.add(token)\n",
    "  \n",
    "  for token in target_doc.split():\n",
    "    target_tokens.add(token)\n",
    "\n",
    "print(f\"Processed {len(input_docs)} sentences\")\n",
    "print(f\"English vocabulary: {len(input_tokens)} tokens\")\n",
    "print(f\"Italian vocabulary: {len(target_tokens)} tokens\")\n",
    "\n",
    "# Sort vocabularies\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "# Use consistent tokenization\n",
    "max_encoder_seq_length = max([len(doc.split()) for doc in input_docs])\n",
    "max_decoder_seq_length = max([len(doc.split()) for doc in target_docs])\n",
    "\n",
    "print(f\"Max encoder sequence length: {max_encoder_seq_length}\")\n",
    "print(f\"Max decoder sequence length: {max_decoder_seq_length}\")\n",
    "\n",
    "# Build dictionaries\n",
    "input_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n",
    "reverse_input_features_dict = dict((i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict((i, token) for token, i in target_features_dict.items())\n",
    "\n",
    "print(\"Creating training matrices...\")\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "print(\"Filling matrices with one-hot encoded data...\")\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "  if line % 1000 == 0:\n",
    "    print(f\"Processing sentence {line}/{len(input_docs)}...\")\n",
    "  \n",
    "  # Use consistent tokenization (.split() instead of regex)\n",
    "  for timestep, token in enumerate(input_doc.split()):\n",
    "    if timestep < max_encoder_seq_length:\n",
    "      encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "  \n",
    "  for timestep, token in enumerate(target_doc.split()):\n",
    "    if timestep < max_decoder_seq_length:\n",
    "      decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "      if timestep > 0:\n",
    "        decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\n",
    "\n",
    "print(\"Data preprocessing complete!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee35873",
   "metadata": {},
   "source": [
    "# **Model Building, Training, and Inference Setup**\n",
    "\n",
    "### **Hyperparameters**\n",
    "```python\n",
    "latent_dim = 256   # LSTM memory size\n",
    "batch_size = 64    # Sentences per update\n",
    "epochs = 100       # Training iterations\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Encoder Architecture**\n",
    "```python\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "```\n",
    "- Processes English sentences\n",
    "- Outputs two 256-dim vectors (hidden + cell states)\n",
    "- These states capture sentence \"meaning\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Decoder Architecture**\n",
    "```python\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "```\n",
    "- Receives Italian sentences (with `<START>`)\n",
    "- **Key**: `initial_state=encoder_states` connects to encoder\n",
    "- Dense layer converts to vocabulary probabilities\n",
    "\n",
    "---\n",
    "\n",
    "### **Training Model**\n",
    "```python\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "- Combines encoder + decoder\n",
    "- Learns by comparing predictions to targets\n",
    "\n",
    "**Training:**\n",
    "```python\n",
    "history = training_model.fit(\n",
    "    [encoder_input_data, decoder_input_data], \n",
    "    decoder_target_data,\n",
    "    batch_size=64, epochs=100, validation_split=0.2\n",
    ")\n",
    "```\n",
    "- 100 passes through data\n",
    "- 80% training, 20% validation\n",
    "- Target: >80% accuracy\n",
    "\n",
    "---\n",
    "\n",
    "### **Inference Models**\n",
    "```python\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "```\n",
    "\n",
    "**Why separate models?**\n",
    "- **encoder_model**: Encode English once → get states\n",
    "- **decoder_model**: Generate Italian word-by-word in loop\n",
    "\n",
    "**Translation flow:**\n",
    "```\n",
    "English → encoder_model → states\n",
    "Loop: word + states → decoder_model → next_word + new_states\n",
    "Until: <END> predicted\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Success Indicators**\n",
    "\n",
    "**Good training:**\n",
    "```\n",
    "accuracy: 0.87 - val_accuracy: 0.83  ✓\n",
    "```\n",
    "\n",
    "**Poor training:**\n",
    "```\n",
    "accuracy: 0.27 - val_accuracy: 0.23  ✗\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875bbce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "\n",
      "Model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">939</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2692</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,224,704</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,019,776</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">691,844</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2692</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m939\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m2692\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │  \u001b[38;5;34m1,224,704\u001b[0m │ input_layer_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m3,019,776\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │    \u001b[38;5;34m691,844\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m2692\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,936,324</span> (18.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,936,324\u001b[0m (18.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,936,324</span> (18.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,936,324\u001b[0m (18.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling model...\n",
      "\n",
      "Training model...\n",
      "Epoch 1/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.1046 - loss: 2.9542 - val_accuracy: 0.1445 - val_loss: 2.1951\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.1403 - loss: 1.9128 - val_accuracy: 0.1415 - val_loss: 2.1923\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.1496 - loss: 1.8344 - val_accuracy: 0.1414 - val_loss: 2.1825\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.1553 - loss: 1.7943 - val_accuracy: 0.1427 - val_loss: 2.1350\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.1628 - loss: 1.7677 - val_accuracy: 0.1435 - val_loss: 2.0915\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.1642 - loss: 1.7344 - val_accuracy: 0.1451 - val_loss: 2.0796\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.1649 - loss: 1.7073 - val_accuracy: 0.1436 - val_loss: 2.0603\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.1680 - loss: 1.6698 - val_accuracy: 0.1463 - val_loss: 2.0732\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.1701 - loss: 1.6646 - val_accuracy: 0.1433 - val_loss: 2.0703\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.1742 - loss: 1.6344 - val_accuracy: 0.1537 - val_loss: 1.9950\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.1780 - loss: 1.6162 - val_accuracy: 0.1527 - val_loss: 1.9972\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.1845 - loss: 1.5942 - val_accuracy: 0.1461 - val_loss: 2.0534\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.1841 - loss: 1.5650 - val_accuracy: 0.1647 - val_loss: 1.9420\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.1897 - loss: 1.5562 - val_accuracy: 0.1468 - val_loss: 2.0084\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.1910 - loss: 1.5245 - val_accuracy: 0.1509 - val_loss: 1.9547\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.1967 - loss: 1.4910 - val_accuracy: 0.1610 - val_loss: 1.9129\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2035 - loss: 1.4695 - val_accuracy: 0.1909 - val_loss: 1.8724\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.2090 - loss: 1.4349 - val_accuracy: 0.1935 - val_loss: 1.8740\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.2106 - loss: 1.4085 - val_accuracy: 0.1945 - val_loss: 1.8647\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.2167 - loss: 1.3806 - val_accuracy: 0.1918 - val_loss: 1.8204\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.2178 - loss: 1.3486 - val_accuracy: 0.2019 - val_loss: 1.7837\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.2210 - loss: 1.3230 - val_accuracy: 0.2020 - val_loss: 1.7622\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2241 - loss: 1.2941 - val_accuracy: 0.1988 - val_loss: 1.7603\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2247 - loss: 1.2552 - val_accuracy: 0.2047 - val_loss: 1.7434\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2261 - loss: 1.2552 - val_accuracy: 0.1954 - val_loss: 1.7744\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2272 - loss: 1.2386 - val_accuracy: 0.2020 - val_loss: 1.7273\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2302 - loss: 1.2161 - val_accuracy: 0.2121 - val_loss: 1.7084\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2315 - loss: 1.1861 - val_accuracy: 0.2125 - val_loss: 1.7159\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.2326 - loss: 1.1516 - val_accuracy: 0.2153 - val_loss: 1.6843\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2346 - loss: 1.1420 - val_accuracy: 0.2131 - val_loss: 1.6654\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2355 - loss: 1.1195 - val_accuracy: 0.2142 - val_loss: 1.6741\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2396 - loss: 1.1011 - val_accuracy: 0.2192 - val_loss: 1.6613\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2393 - loss: 1.0923 - val_accuracy: 0.2217 - val_loss: 1.6619\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2395 - loss: 1.0638 - val_accuracy: 0.2203 - val_loss: 1.6468\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2391 - loss: 1.0666 - val_accuracy: 0.2211 - val_loss: 1.6586\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.2431 - loss: 1.0280 - val_accuracy: 0.2205 - val_loss: 1.6225\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2432 - loss: 1.0210 - val_accuracy: 0.2210 - val_loss: 1.6408\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2439 - loss: 1.0246 - val_accuracy: 0.2280 - val_loss: 1.6155\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2462 - loss: 1.0020 - val_accuracy: 0.2281 - val_loss: 1.6296\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2448 - loss: 0.9883 - val_accuracy: 0.2228 - val_loss: 1.6223\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2482 - loss: 0.9701 - val_accuracy: 0.2289 - val_loss: 1.6250\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2515 - loss: 0.9366 - val_accuracy: 0.2312 - val_loss: 1.6028\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.2505 - loss: 0.9274 - val_accuracy: 0.2289 - val_loss: 1.5975\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2510 - loss: 0.9245 - val_accuracy: 0.2321 - val_loss: 1.6082\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2536 - loss: 0.9146 - val_accuracy: 0.2322 - val_loss: 1.6110\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2535 - loss: 0.8944 - val_accuracy: 0.2331 - val_loss: 1.6123\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2543 - loss: 0.8911 - val_accuracy: 0.2358 - val_loss: 1.5925\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2555 - loss: 0.8770 - val_accuracy: 0.2389 - val_loss: 1.6049\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2566 - loss: 0.8580 - val_accuracy: 0.2384 - val_loss: 1.5864\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2584 - loss: 0.8424 - val_accuracy: 0.2384 - val_loss: 1.5946\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.2640 - loss: 0.8339 - val_accuracy: 0.2404 - val_loss: 1.5905\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2607 - loss: 0.8214 - val_accuracy: 0.2383 - val_loss: 1.5978\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.2625 - loss: 0.8120 - val_accuracy: 0.2384 - val_loss: 1.6069\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.2759 - loss: 0.7991 - val_accuracy: 0.2399 - val_loss: 1.5978\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2636 - loss: 0.7922 - val_accuracy: 0.2434 - val_loss: 1.5763\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.2637 - loss: 0.7846 - val_accuracy: 0.2442 - val_loss: 1.5947\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2658 - loss: 0.7718 - val_accuracy: 0.2447 - val_loss: 1.6193\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2656 - loss: 0.7640 - val_accuracy: 0.2431 - val_loss: 1.6093\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2687 - loss: 0.7406 - val_accuracy: 0.2408 - val_loss: 1.6266\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2770 - loss: 0.7391 - val_accuracy: 0.2445 - val_loss: 1.6113\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2714 - loss: 0.7237 - val_accuracy: 0.2428 - val_loss: 1.6259\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2685 - loss: 0.7244 - val_accuracy: 0.2455 - val_loss: 1.5979\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2730 - loss: 0.7124 - val_accuracy: 0.2463 - val_loss: 1.6161\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.2727 - loss: 0.7005 - val_accuracy: 0.2459 - val_loss: 1.6177\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2737 - loss: 0.6936 - val_accuracy: 0.2447 - val_loss: 1.6259\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2729 - loss: 0.6828 - val_accuracy: 0.2432 - val_loss: 1.6461\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2739 - loss: 0.6785 - val_accuracy: 0.2439 - val_loss: 1.6169\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2749 - loss: 0.6643 - val_accuracy: 0.2468 - val_loss: 1.6309\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2755 - loss: 0.6590 - val_accuracy: 0.2476 - val_loss: 1.6414\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2804 - loss: 0.6535 - val_accuracy: 0.2449 - val_loss: 1.6503\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2816 - loss: 0.6454 - val_accuracy: 0.2471 - val_loss: 1.6779\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2790 - loss: 0.6326 - val_accuracy: 0.2474 - val_loss: 1.6731\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2789 - loss: 0.6410 - val_accuracy: 0.2444 - val_loss: 1.6805\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2805 - loss: 0.6253 - val_accuracy: 0.2487 - val_loss: 1.6626\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2845 - loss: 0.6217 - val_accuracy: 0.2463 - val_loss: 1.6509\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2853 - loss: 0.6087 - val_accuracy: 0.2479 - val_loss: 1.6779\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2850 - loss: 0.6051 - val_accuracy: 0.2487 - val_loss: 1.6793\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.2828 - loss: 0.5908 - val_accuracy: 0.2485 - val_loss: 1.6934\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.2851 - loss: 0.5846 - val_accuracy: 0.2465 - val_loss: 1.6892\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2865 - loss: 0.5794 - val_accuracy: 0.2484 - val_loss: 1.6982\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2839 - loss: 0.5719 - val_accuracy: 0.2458 - val_loss: 1.7088\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2864 - loss: 0.5648 - val_accuracy: 0.2472 - val_loss: 1.7084\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2895 - loss: 0.5605 - val_accuracy: 0.2483 - val_loss: 1.7114\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2885 - loss: 0.5562 - val_accuracy: 0.2487 - val_loss: 1.7238\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.2883 - loss: 0.5549 - val_accuracy: 0.2471 - val_loss: 1.7123\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2892 - loss: 0.5397 - val_accuracy: 0.2447 - val_loss: 1.7240\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2921 - loss: 0.5359 - val_accuracy: 0.2483 - val_loss: 1.7135\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2935 - loss: 0.5301 - val_accuracy: 0.2492 - val_loss: 1.7482\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2946 - loss: 0.5300 - val_accuracy: 0.2494 - val_loss: 1.7457\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.2942 - loss: 0.5145 - val_accuracy: 0.2485 - val_loss: 1.7342\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2936 - loss: 0.5097 - val_accuracy: 0.2484 - val_loss: 1.7471\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.2935 - loss: 0.5103 - val_accuracy: 0.2467 - val_loss: 1.7374\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.2976 - loss: 0.5003 - val_accuracy: 0.2455 - val_loss: 1.7647\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.2941 - loss: 0.4933 - val_accuracy: 0.2445 - val_loss: 1.7642\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.2988 - loss: 0.4947 - val_accuracy: 0.2511 - val_loss: 1.7742\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2982 - loss: 0.4883 - val_accuracy: 0.2456 - val_loss: 1.7823\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.2977 - loss: 0.4848 - val_accuracy: 0.2456 - val_loss: 1.7760\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.3000 - loss: 0.4839 - val_accuracy: 0.2453 - val_loss: 1.8100\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2988 - loss: 0.4795 - val_accuracy: 0.2472 - val_loss: 1.8270\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.2998 - loss: 0.4737 - val_accuracy: 0.2487 - val_loss: 1.8177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model...\n",
      "\n",
      "Building inference models...\n"
     ]
    }
   ],
   "source": [
    "# MODEL BUILDING\n",
    "print(\"Building model...\")\n",
    "latent_dim = 256\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(\n",
    "    decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Training model\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "print(\"\\nModel summary:\")\n",
    "training_model.summary()\n",
    "\n",
    "print(\"\\nCompiling model...\")\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nTraining model...\")\n",
    "history = training_model.fit(\n",
    "    [encoder_input_data, decoder_input_data], \n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nSaving model...\")\n",
    "training_model.save('training_model.h5')\n",
    "\n",
    "# INFERENCE MODELS\n",
    "print(\"\\nBuilding inference models...\")\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94911bd1",
   "metadata": {},
   "source": [
    "## **Translation Function and Testing**\n",
    "\n",
    "### **The decode_sequence() Function**\n",
    "\n",
    "**Purpose:** Translates English to Italian word-by-word using inference models\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Encode Input**\n",
    "```python\n",
    "states_value = encoder_model.predict(test_input, verbose=0)\n",
    "```\n",
    "- Processes English sentence through encoder\n",
    "- Returns meaning vectors (2 × 256-dim states)\n",
    "- Run **once** per translation\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Initialize Decoder**\n",
    "```python\n",
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "decoded_sentence = ''\n",
    "stop_condition = False\n",
    "```\n",
    "- Create one-hot encoded `<START>` token\n",
    "- Empty string to build translation\n",
    "- Loop flag\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Generation Loop**\n",
    "```python\n",
    "while not stop_condition:\n",
    "    output_tokens, hidden_state, cell_state = decoder_model.predict(\n",
    "        [target_seq] + states_value, verbose=0)\n",
    "```\n",
    "- Pass current word + states to decoder\n",
    "- Get probabilities for next word + updated states\n",
    "\n",
    "**Pick highest probability word:**\n",
    "```python\n",
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "decoded_sentence += \" \" + sampled_token\n",
    "```\n",
    "- Find max probability index\n",
    "- Convert index to Italian word\n",
    "- Add to translation\n",
    "\n",
    "**Check stop conditions:**\n",
    "```python\n",
    "if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "    stop_condition = True\n",
    "```\n",
    "- Stop if predicted `<END>` (natural end)\n",
    "- Or if exceeded max length (safety)\n",
    "\n",
    "**Update for next iteration:**\n",
    "```python\n",
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq[0, 0, sampled_token_index] = 1.\n",
    "states_value = [hidden_state, cell_state]\n",
    "```\n",
    "- Encode predicted word as next input\n",
    "- Update states with new context\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Return Result**\n",
    "```python\n",
    "return decoded_sentence.strip().replace(' <END>', '')\n",
    "```\n",
    "- Remove leading/trailing spaces\n",
    "- Remove `<END>` token from output\n",
    "\n",
    "---\n",
    "\n",
    "### **Translation Flow Example**\n",
    "```\n",
    "Input: \"Go .\"\n",
    "\n",
    "Encode: \"Go .\" → states\n",
    "\n",
    "Loop iteration 1:\n",
    "  \"<START>\" + states → \"Vai\" (82%) + new_states\n",
    "  Result: \" Vai\"\n",
    "\n",
    "Loop iteration 2:\n",
    "  \"Vai\" + new_states → \".\" (88%) + newer_states\n",
    "  Result: \" Vai .\"\n",
    "\n",
    "Loop iteration 3:\n",
    "  \".\" + newer_states → \"<END>\" (91%)\n",
    "  STOP!\n",
    "\n",
    "Output: \"Vai .\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Testing the Translator**\n",
    "```python\n",
    "for seq_index in range(min(20, len(input_docs))):\n",
    "    test_input = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(test_input)\n",
    "    print('Input:', input_docs[seq_index])\n",
    "    print('Decoded:', decoded_sentence)\n",
    "```\n",
    "- Tests first 20 training sentences\n",
    "- Should translate accurately if training was successful\n",
    "\n",
    "---\n",
    "\n",
    "### **Expected Output (Good Training)**\n",
    "```\n",
    "Input: Go .\n",
    "Decoded: Vai .\n",
    "\n",
    "Input: Hi .\n",
    "Decoded: Ciao .\n",
    "\n",
    "Input: Run !\n",
    "Decoded: Corri !\n",
    "```\n",
    "\n",
    "### **Bad Output (Poor Training)**\n",
    "```\n",
    "Input: Go .\n",
    "Decoded: Si !\n",
    "\n",
    "Input: Hi .\n",
    "Decoded: Si !\n",
    "\n",
    "Input: Run !\n",
    "Decoded: ! !\n",
    "```\n",
    "- Repetitive/wrong translations = model didn't learn\n",
    "- Need higher training accuracy (>80%)\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts**\n",
    "\n",
    "✅ **Autoregressive generation**: Each word becomes input for next\n",
    "✅ **Greedy decoding**: Always picks highest probability\n",
    "✅ **State updates**: Carry context through generation\n",
    "✅ **Stop conditions**: Natural (`<END>`) or max length safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb22ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing translations on training data:\n",
      "-\n",
      "Input: Hi .\n",
      "Decoded: Ciao !\n",
      "-\n",
      "Input: Hi .\n",
      "Decoded: Ciao !\n",
      "-\n",
      "Input: Run !\n",
      "Decoded: Corra !\n",
      "-\n",
      "Input: Run !\n",
      "Decoded: Corra !\n",
      "-\n",
      "Input: Run !\n",
      "Decoded: Corra !\n",
      "-\n",
      "Input: Who ?\n",
      "Decoded: Chi ?\n",
      "-\n",
      "Input: Wow !\n",
      "Decoded: ! ! ! . . .\n",
      "-\n",
      "Input: Duck !\n",
      "Decoded: Si !\n",
      "-\n",
      "Input: Duck !\n",
      "Decoded: Si !\n",
      "-\n",
      "Input: Duck !\n",
      "Decoded: Si !\n",
      "-\n",
      "Input: Duck !\n",
      "Decoded: Si !\n",
      "-\n",
      "Input: Duck !\n",
      "Decoded: Si !\n",
      "-\n",
      "Input: Duck !\n",
      "Decoded: Si !\n",
      "-\n",
      "Input: Duck !\n",
      "Decoded: Si !\n",
      "-\n",
      "Input: Duck !\n",
      "Decoded: Si !\n",
      "-\n",
      "Input: Jump !\n",
      "Decoded: Salti !\n",
      "-\n",
      "Input: Jump !\n",
      "Decoded: Salti !\n",
      "-\n",
      "Input: Jump !\n",
      "Decoded: Salti !\n",
      "-\n",
      "Input: Jump .\n",
      "Decoded: Salti .\n",
      "-\n",
      "Input: Jump .\n",
      "Decoded: Salti .\n"
     ]
    }
   ],
   "source": [
    "# TRANSLATION FUNCTION\n",
    "def decode_sequence(test_input):\n",
    "  states_value = encoder_model.predict(test_input, verbose=0)\n",
    "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "  target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "  \n",
    "  decoded_sentence = ''\n",
    "  stop_condition = False\n",
    "  \n",
    "  while not stop_condition:\n",
    "    output_tokens, hidden_state, cell_state = decoder_model.predict(\n",
    "        [target_seq] + states_value, verbose=0)\n",
    "    \n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "    decoded_sentence += \" \" + sampled_token\n",
    "    \n",
    "    if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "      stop_condition = True\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "    states_value = [hidden_state, cell_state]\n",
    "  \n",
    "  return decoded_sentence.strip().replace(' <END>', '')\n",
    "\n",
    "# TEST TRANSLATIONS\n",
    "print(\"\\nTesting translations on training data:\")\n",
    "for seq_index in range(min(20, len(input_docs))):  # Test first 20\n",
    "  test_input = encoder_input_data[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(test_input)\n",
    "  print('-')\n",
    "  print('Input:', input_docs[seq_index])\n",
    "  print('Decoded:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9ec18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
